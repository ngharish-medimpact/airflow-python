apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-worker
  namespace: pdp-dev
  labels:
    tier: airflow
    component: worker
spec:
  serviceName: airflow-worker
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: worker
  template:
    metadata:
      labels:
        tier: airflow
        component: worker
      # annotations:
      #   checksum/configmap: 5873919b552e6912c3de9638c4c348f95c27633e3a891787d559a441a3910ffb
      #   checksum/secrets: ~
    spec:
      terminationGracePeriodSeconds: 600
      restartPolicy: Always
      serviceAccountName: "airflow-worker"
      securityContext:
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: dag-fetcher
          image: docker-local.artifactory.medimpact.com/com/medimpact/pdp/medgen-dags-python:0.0.6
          imagePullPolicy: Always
          command:
            - "rsync"
            - "-av"
            - "--no-times"
            - "--no-perms"
            - "/source_files/dags/"
            - "/dags/"
          volumeMounts:
            - name: dags-volume
              mountPath: "/dags"
        - name: wait-for-airflow-migrations
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          image: docker-local.artifactory.medimpact.com/dockerhub/apache/airflow:slim-3.0.2
          imagePullPolicy: Always
          command:
            - "/bin/bash"
            - "-c"
            - |
              exec /entrypoint airflow db check-migrations --migration-wait-timeout=60
          env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-creds
                  key: postgres_password
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: postgresql+psycopg2://airflow_user:$(POSTGRES_PASSWORD)@devedb0-vip.medimpact.com:5432/pdp_airflow_db
      containers:
        - name: worker
          image: docker-local.artifactory.medimpact.com/dockerhub/apache/airflow:slim-3.0.2
          imagePullPolicy: Always
          args:
            - "bash"
            - "-c"
            - "exec airflow celery worker"
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          ports:
            - name: worker-logs
              containerPort: 8793
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --local --job-type WorkerJob
          volumeMounts:
            - name: dags-volume
              mountPath: "/opt/airflow/dags"
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: CeleryExecutor
            - name: AIRFLOW__CORE__LOAD_EXAMPLES
              value: "False"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-creds
                  key: postgres_password
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: postgresql+psycopg2://airflow_user:$(POSTGRES_PASSWORD)@devedb0-vip.medimpact.com:5432/pdp_airflow_db
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-redis-password
                  key: password
            - name: AIRFLOW__CELERY__RESULT_BACKEND
              value: "db+redis://:$(REDIS_PASSWORD)@airflow-redis:6379/1"
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
        - name: worker-log-groomer
          image: docker-local.artifactory.medimpact.com/dockerhub/apache/airflow:slim-3.0.2
          imagePullPolicy: Always
          resources:
            {}
          args:
            - "bash"
            - "-c"
            - |
              sleep 60
              exec \
              airflow jobs check --local --job-type WorkerJob --hostname $(hostname)
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
      volumes:
        - name: dags-volume
          emptyDir: {}
        - name: config
          configMap:
            name: airflow-config
        - name: logs
          emptyDir: {}